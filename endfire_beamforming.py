"""
AirPods ã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ã‚¢å‹ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°
==========================================

ä¸€ç›´ç·šä¸Šã®é…ç½®ã§è©±è€…Aã®éŸ³å£°ã®ã¿ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›

é…ç½®:
A â†---â†’ å·¦AirPods â†--50cm--â†’ å³AirPods â†---â†’ B

å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
pip install numpy scipy sounddevice

ä½¿ç”¨æ–¹æ³•:
1. AirPodsã‚’50cmé›¢ã—ã¦ä¸€ç›´ç·šä¸Šã«é…ç½®
2. è©±è€…Aã¨BãŒä¸¡ç«¯ã«ä½ç½®
3. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
4. è©±è€…Aã®éŸ³å£°ã®ã¿ãŒMacBookã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‹ã‚‰å‡ºåŠ›ã•ã‚Œã‚‹
"""

import numpy as np
import sounddevice as sd
from scipy import signal
from scipy.fft import fft, ifft
import queue
import threading
import time


class EndfireBeamformer:
    """ã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ã‚¢å‹ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 sample_rate=48000,
                 block_size=2048,  # ä½é…å»¶ã®ãŸã‚å°ã•ã‚ã«è¨­å®š
                 mic_distance=0.50,  # 50cm
                 sound_speed=343.0,
                 target_direction='left'):  # 'left' = Aå´, 'right' = Bå´
        """
        Parameters:
        -----------
        sample_rate : int
            ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆHzï¼‰
        block_size : int
            å‡¦ç†ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºï¼ˆå°ã•ã„ã»ã©ä½é…å»¶ï¼‰
        mic_distance : float
            å·¦å³ãƒã‚¤ã‚¯é–“ã®è·é›¢ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰
        sound_speed : float
            éŸ³é€Ÿï¼ˆm/sï¼‰
        target_direction : str
            ç›®çš„æ–¹å‘ ('left' = Aå´, 'right' = Bå´)
        """
        self.sample_rate = sample_rate
        self.block_size = block_size
        self.mic_distance = mic_distance
        self.sound_speed = sound_speed
        self.target_direction = target_direction
        
        # å…¥å‡ºåŠ›ã‚­ãƒ¥ãƒ¼
        self.input_queue = queue.Queue(maxsize=10)
        self.output_queue = queue.Queue(maxsize=10)
        
        # å‡¦ç†çŠ¶æ…‹
        self.is_running = False
        self.processing_thread = None
        
        # ã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ã‚¢ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.max_delay_samples = int(self.mic_distance / self.sound_speed * self.sample_rate)
        
        print(f"\n=== ã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ã‚¢å‹ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚° ===")
        print(f"ãƒã‚¤ã‚¯é–“è·é›¢: {self.mic_distance*100:.1f} cm")
        print(f"æœ€å¤§é…å»¶: {self.max_delay_samples} ã‚µãƒ³ãƒ—ãƒ« ({self.max_delay_samples/self.sample_rate*1000:.2f} ms)")
        print(f"ç›®çš„æ–¹å‘: {'Aå´ï¼ˆå·¦ï¼‰' if target_direction == 'left' else 'Bå´ï¼ˆå³ï¼‰'}")
        print(f"ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º: {block_size} ã‚µãƒ³ãƒ—ãƒ« ({block_size/sample_rate*1000:.1f} ms)")
    
    def list_audio_devices(self):
        """åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤º"""
        print("\n=== åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ ===")
        devices = sd.query_devices()
        
        print("\nã€å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã€‘")
        for i, device in enumerate(devices):
            if device['max_input_channels'] >= 2:
                print(f"[{i}] {device['name']}")
                print(f"    å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {device['max_input_channels']}")
                print(f"    ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {device['default_samplerate']} Hz")
                print()
        
        print("ã€å‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹ã€‘")
        for i, device in enumerate(devices):
            if device['max_output_channels'] >= 1:
                print(f"[{i}] {device['name']}")
                print(f"    å‡ºåŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {device['max_output_channels']}")
                print()
        
        return devices
    
    def select_device(self, device_type='input'):
        """ãƒ‡ãƒã‚¤ã‚¹ã‚’é¸æŠ"""
        devices = sd.query_devices()
        
        if device_type == 'input':
            # AirPodsã‚’è‡ªå‹•æ¤œå‡º
            airpods_indices = []
            for i, device in enumerate(devices):
                if 'airpods' in device['name'].lower() and device['max_input_channels'] >= 2:
                    airpods_indices.append(i)
            
            if len(airpods_indices) == 1:
                device_id = airpods_indices[0]
                print(f"\nAirPodsã‚’æ¤œå‡ºã—ã¾ã—ãŸ: {devices[device_id]['name']}")
                return device_id
            elif len(airpods_indices) > 1:
                print("\nè¤‡æ•°ã®AirPodsãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
                for idx in airpods_indices:
                    print(f"[{idx}] {devices[idx]['name']}")
                device_id = int(input("ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: "))
                return device_id
            else:
                print("\nAirPodsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                self.list_audio_devices()
                device_id = int(input("å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: "))
                return device_id
        else:
            # å‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹ï¼ˆMacBookã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ï¼‰
            macbook_indices = []
            for i, device in enumerate(devices):
                if ('macbook' in device['name'].lower() or 
                    'built-in' in device['name'].lower()) and device['max_output_channels'] >= 1:
                    macbook_indices.append(i)
            
            if macbook_indices:
                device_id = macbook_indices[0]
                print(f"\nå‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹: {devices[device_id]['name']}")
                return device_id
            else:
                print("\nMacBookã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                self.list_audio_devices()
                device_id = int(input("å‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: "))
                return device_id
    
    def endfire_beamforming_time_domain(self, left_channel, right_channel):
        """
        æ™‚é–“é ˜åŸŸã§ã®ã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ã‚¢å‹ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°ï¼ˆä½é…å»¶ç‰ˆï¼‰
        
        Parameters:
        -----------
        left_channel : ndarray
            å·¦ãƒãƒ£ãƒ³ãƒãƒ«ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        right_channel : ndarray
            å³ãƒãƒ£ãƒ³ãƒãƒ«ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        
        Returns:
        --------
        output : ndarray
            ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°å¾Œã®éŸ³å£°
        """
        # é…å»¶ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¨ˆç®—
        delay_samples = self.max_delay_samples
        
        if self.target_direction == 'left':
            # Aå´ï¼ˆå·¦ï¼‰ã‚’å¼·èª¿: å·¦ãƒã‚¤ã‚¯ã‚’ãã®ã¾ã¾ã€å³ãƒã‚¤ã‚¯ã‚’é…å»¶ã•ã›ã¦æ¸›ç®—
            # å·¦ã‹ã‚‰æ¥ã‚‹éŸ³ã¯åŒç›¸ã€å³ã‹ã‚‰æ¥ã‚‹éŸ³ã¯é€†ç›¸ã«ãªã‚‹
            delayed_right = np.pad(right_channel, (delay_samples, 0), mode='constant')[:-delay_samples]
            output = left_channel - 0.5 * delayed_right
        else:
            # Bå´ï¼ˆå³ï¼‰ã‚’å¼·èª¿: å³ãƒã‚¤ã‚¯ã‚’ãã®ã¾ã¾ã€å·¦ãƒã‚¤ã‚¯ã‚’é…å»¶ã•ã›ã¦æ¸›ç®—
            delayed_left = np.pad(left_channel, (delay_samples, 0), mode='constant')[:-delay_samples]
            output = right_channel - 0.5 * delayed_left
        
        return output
    
    def endfire_beamforming_frequency_domain(self, left_channel, right_channel):
        """
        å‘¨æ³¢æ•°é ˜åŸŸã§ã®ã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ã‚¢å‹ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°ï¼ˆé«˜å“è³ªç‰ˆï¼‰
        
        Parameters:
        -----------
        left_channel : ndarray
            å·¦ãƒãƒ£ãƒ³ãƒãƒ«ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        right_channel : ndarray
            å³ãƒãƒ£ãƒ³ãƒãƒ«ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        
        Returns:
        --------
        output : ndarray
            ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°å¾Œã®éŸ³å£°
        """
        # FFTã§å‘¨æ³¢æ•°é ˜åŸŸã«å¤‰æ›
        left_fft = fft(left_channel)
        right_fft = fft(right_channel)
        
        # å‘¨æ³¢æ•°ãƒ“ãƒ³ã‚’è¨ˆç®—
        freqs = np.fft.fftfreq(len(left_channel), 1/self.sample_rate)
        
        # å‡ºåŠ›ä¿¡å·ã‚’åˆæœŸåŒ–
        output_fft = np.zeros_like(left_fft, dtype=complex)
        
        # å„å‘¨æ³¢æ•°ãƒ“ãƒ³ã«å¯¾ã—ã¦ã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ã‚¢ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°
        for i, freq in enumerate(freqs[:len(freqs)//2 + 1]):
            if freq == 0:
                # DCæˆåˆ†
                if self.target_direction == 'left':
                    output_fft[i] = left_fft[i]
                else:
                    output_fft[i] = right_fft[i]
                continue
            
            # æ™‚é–“é…å»¶ã«å¯¾å¿œã™ã‚‹ä½ç›¸é…å»¶
            time_delay = self.mic_distance / self.sound_speed
            phase_delay = 2 * np.pi * abs(freq) * time_delay
            
            if self.target_direction == 'left':
                # Aå´ï¼ˆå·¦ï¼‰ã‚’å¼·èª¿
                # å·¦ãƒã‚¤ã‚¯ + å³ãƒã‚¤ã‚¯ Ã— ä½ç›¸é…å»¶ Ã— æ¸›è¡°ä¿‚æ•°
                weight_left = 1.0
                weight_right = -0.5 * np.exp(-1j * phase_delay)
                output_fft[i] = weight_left * left_fft[i] + weight_right * right_fft[i]
            else:
                # Bå´ï¼ˆå³ï¼‰ã‚’å¼·èª¿
                weight_right = 1.0
                weight_left = -0.5 * np.exp(-1j * phase_delay)
                output_fft[i] = weight_right * right_fft[i] + weight_left * left_fft[i]
            
            # è² ã®å‘¨æ³¢æ•°æˆåˆ†ã‚‚å¯¾ç§°ã«è¨­å®š
            if i > 0 and i < len(freqs)//2:
                output_fft[-i] = output_fft[i].conj()
        
        # æ™‚é–“é ˜åŸŸã«æˆ»ã™
        output = np.real(ifft(output_fft))
        
        return output
    
    def apply_noise_reduction(self, audio_data):
        """ç°¡æ˜“ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³"""
        # ãƒã‚¤ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆä½å‘¨æ³¢ãƒã‚¤ã‚ºé™¤å»ï¼‰
        sos = signal.butter(4, 100, 'hp', fs=self.sample_rate, output='sos')
        filtered = signal.sosfilt(sos, audio_data)
        
        # ãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆé«˜å‘¨æ³¢ãƒã‚¤ã‚ºé™¤å»ï¼‰
        sos = signal.butter(4, 8000, 'lp', fs=self.sample_rate, output='sos')
        filtered = signal.sosfilt(sos, filtered)
        
        return filtered
    
    def processing_loop(self, method='frequency'):
        """éŸ³å£°å‡¦ç†ãƒ«ãƒ¼ãƒ—ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰"""
        print("\nå‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹...")
        
        while self.is_running:
            try:
                # å…¥åŠ›ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                audio_data = self.input_queue.get(timeout=0.1)
                
                # å·¦å³ãƒãƒ£ãƒ³ãƒãƒ«ã‚’åˆ†é›¢
                left_channel = audio_data[:, 0]
                right_channel = audio_data[:, 1]
                
                # ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°
                if method == 'time':
                    output = self.endfire_beamforming_time_domain(left_channel, right_channel)
                else:
                    output = self.endfire_beamforming_frequency_domain(left_channel, right_channel)
                
                # ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³
                output = self.apply_noise_reduction(output)
                
                # æ­£è¦åŒ–ï¼ˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢ï¼‰
                max_val = np.max(np.abs(output))
                if max_val > 0.8:
                    output = output * 0.8 / max_val
                
                # å‡ºåŠ›ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                try:
                    self.output_queue.put_nowait(output)
                except queue.Full:
                    # ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã®å ´åˆã¯å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’ç ´æ£„
                    try:
                        self.output_queue.get_nowait()
                        self.output_queue.put_nowait(output)
                    except:
                        pass
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print("å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†")
    
    def audio_input_callback(self, indata, frames, time_info, status):
        """å…¥åŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if status:
            print(f"å…¥åŠ›Status: {status}")
        
        try:
            self.input_queue.put_nowait(indata.copy())
        except queue.Full:
            # ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã®å ´åˆã¯è­¦å‘Šï¼ˆãƒ‡ãƒ¼ã‚¿æå¤±ï¼‰
            pass
    
    def audio_output_callback(self, outdata, frames, time_info, status):
        """å‡ºåŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if status:
            print(f"å‡ºåŠ›Status: {status}")
        
        try:
            data = self.output_queue.get_nowait()
            outdata[:, 0] = data
        except queue.Empty:
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç„¡éŸ³
            outdata.fill(0)
    
    def run_realtime(self, method='frequency', duration=None):
        """
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’å®Ÿè¡Œ
        
        Parameters:
        -----------
        method : str
            å‡¦ç†æ–¹æ³• ('time' = æ™‚é–“é ˜åŸŸ, 'frequency' = å‘¨æ³¢æ•°é ˜åŸŸ)
        duration : float or None
            å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰ã€‚Noneã®å ´åˆã¯æ‰‹å‹•åœæ­¢ã¾ã§ç¶™ç¶š
        """
        print(f"\n=== ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©±è€…åˆ†é›¢é–‹å§‹ ===")
        print(f"å‡¦ç†æ–¹æ³•: {'æ™‚é–“é ˜åŸŸï¼ˆä½é…å»¶ï¼‰' if method == 'time' else 'å‘¨æ³¢æ•°é ˜åŸŸï¼ˆé«˜å“è³ªï¼‰'}")
        print(f"ç›®çš„è©±è€…: {'Aï¼ˆå·¦å´ï¼‰' if self.target_direction == 'left' else 'Bï¼ˆå³å´ï¼‰'}")
        
        if duration:
            print(f"å®Ÿè¡Œæ™‚é–“: {duration}ç§’")
        else:
            print("Ctrl+Cã§åœæ­¢ã—ã¦ãã ã•ã„")
        
        # ãƒ‡ãƒã‚¤ã‚¹ã‚’é¸æŠ
        input_device = self.select_device('input')
        output_device = self.select_device('output')
        
        self.is_running = True
        
        # å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
        self.processing_thread = threading.Thread(
            target=self.processing_loop,
            args=(method,),
            daemon=True
        )
        self.processing_thread.start()
        
        start_time = time.time()
        
        try:
            # å…¥å‡ºåŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åŒæ™‚ã«é–‹å§‹
            with sd.InputStream(device=input_device,
                              channels=2,
                              samplerate=self.sample_rate,
                              blocksize=self.block_size,
                              callback=self.audio_input_callback), \
                 sd.OutputStream(device=output_device,
                               channels=1,
                               samplerate=self.sample_rate,
                               blocksize=self.block_size,
                               callback=self.audio_output_callback):
                
                print("\nğŸ¤ éŒ²éŸ³ä¸­... ğŸ”Š å†ç”Ÿä¸­...")
                print("è©±è€…Aã®éŸ³å£°ãŒMacBookã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‹ã‚‰å‡ºåŠ›ã•ã‚Œã¾ã™\n")
                
                while self.is_running:
                    if duration and (time.time() - start_time) >= duration:
                        break
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
                    elapsed = time.time() - start_time
                    queue_status = f"å…¥åŠ›ã‚­ãƒ¥ãƒ¼: {self.input_queue.qsize()}/10, å‡ºåŠ›ã‚­ãƒ¥ãƒ¼: {self.output_queue.qsize()}/10"
                    print(f"\rçµŒéæ™‚é–“: {elapsed:.1f}ç§’ | {queue_status}", end='', flush=True)
                    
                    time.sleep(0.1)
        
        except KeyboardInterrupt:
            print("\n\nåœæ­¢ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"\n\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.is_running = False
            if self.processing_thread:
                self.processing_thread.join(timeout=2.0)
        
        print("\nå‡¦ç†å®Œäº†")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("AirPods ã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ã‚¢å‹ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒŸãƒ³ã‚°")
    print("è©±è€…Aã®éŸ³å£°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›")
    print("=" * 60)
    print()
    print("é…ç½®:")
    print("  A â†---â†’ å·¦AirPods â†--50cm--â†’ å³AirPods â†---â†’ B")
    print()
    
    # ãƒ“ãƒ¼ãƒ ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’åˆæœŸåŒ–
    beamformer = EndfireBeamformer(
        sample_rate=48000,
        block_size=2048,  # ä½é…å»¶
        mic_distance=0.50,  # 50cm
        target_direction='left'  # Aå´ã‚’å‡ºåŠ›
    )
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º
    beamformer.list_audio_devices()
    
    # å®Ÿè¡Œæ™‚é–“ã‚’è¨­å®š
    print("\nå®Ÿè¡Œæ™‚é–“ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆç§’ï¼‰:")
    print("ï¼ˆEnterã‚­ãƒ¼ã®ã¿ã§æ‰‹å‹•åœæ­¢ãƒ¢ãƒ¼ãƒ‰ï¼‰")
    duration_input = input("> ")
    duration = float(duration_input) if duration_input.strip() else None
    
    # å‡¦ç†æ–¹æ³•ã‚’é¸æŠ
    print("\nå‡¦ç†æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1: å‘¨æ³¢æ•°é ˜åŸŸï¼ˆé«˜å“è³ªãƒ»æ¨å¥¨ï¼‰")
    print("2: æ™‚é–“é ˜åŸŸï¼ˆè¶…ä½é…å»¶ï¼‰")
    method_choice = input("> ").strip()
    method = 'time' if method_choice == '2' else 'frequency'
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’å®Ÿè¡Œ
    beamformer.run_realtime(method=method, duration=duration)
    
    print("\nå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")


if __name__ == "__main__":
    main()
